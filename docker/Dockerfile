ARG ARCH=x86_64
# ARCH options: x86_64, aarch64

# -----------------------------------------------------------------------------
# Stage 1: build wheel and ptoas (LLVM is pre-built in ptoas-llvm image)
# -----------------------------------------------------------------------------
# Build LLVM image once with empty context so it never rebuilds from repo changes:
#   docker build -f docker/Dockerfile.llvm -t ptoas-llvm:19 docker/empty
FROM ptoas-llvm:19 AS builder
ARG ARCH=x86_64

# build ptoas (use local source when build context is repo root: docker build -f docker/Dockerfile .)
WORKDIR $WORKSPACE_DIR
COPY . PTOAS

WORKDIR $PTO_SOURCE_DIR
RUN cmake -G Ninja \
    -S . \
    -B build \
    -DLLVM_DIR=$LLVM_BUILD_DIR/lib/cmake/llvm \
    -DMLIR_DIR=$LLVM_BUILD_DIR/lib/cmake/mlir \
    -DPython3_ROOT_DIR=${PY_PATH} \
    -DPython3_EXECUTABLE=${PY_PATH}/bin/python \
    -DPython3_FIND_STRATEGY=LOCATION \
    -Dpybind11_DIR=$(python -m pybind11 --cmakedir) \
    -DMLIR_PYTHON_PACKAGE_DIR=${LLVM_BUILD_DIR}/tools/mlir/python_packages/mlir_core \
    -DCMAKE_INSTALL_PREFIX=${PTO_INSTALL_DIR}

RUN ninja -C build && ninja -C build install

# create python wheel
ENV PY_PACKAGE_DIR=$LLVM_BUILD_DIR/tools/mlir/python_packages/mlir_core/

# copy pto.py, _pto_ops_gen.py 
RUN cp $PTO_INSTALL_DIR/mlir/dialects/*.py $PY_PACKAGE_DIR/mlir/dialects/

COPY docker/setup.py $PY_PACKAGE_DIR/

WORKDIR $PY_PACKAGE_DIR
RUN python setup.py bdist_wheel

# fix missing so
RUN export LD_LIBRARY_PATH=$LLVM_BUILD_DIR/lib:$PTO_INSTALL_DIR/lib:$LD_LIBRARY_PATH \
    && auditwheel repair --plat manylinux_2_34_${ARCH} dist/ptoas*.whl

RUN pip install wheelhouse/ptoas*.whl

# test import without adjusting $PYTHONPATH and $LD_LIBRARY_PATH, in some irrelevant dir
WORKDIR /test
RUN python -c "import mlir.ir"
RUN python -c "from mlir.dialects import pto"

# test ptoas cli
ENV PATH=$PTO_SOURCE_DIR/build/tools/ptoas:$PATH
RUN which ptoas

WORKDIR $PTO_SOURCE_DIR/test/samples/MatMul/
RUN python ./tmatmulk.py > ./tmatmulk.pto
RUN ptoas ./tmatmulk.pto -o ./tmatmulk.cpp

WORKDIR $PTO_SOURCE_DIR/test/samples/Abs/
RUN python ./abs.py > ./abs.pto
RUN ptoas --enable-insert-sync ./abs.pto -o ./abs.cpp

# collect only *.so actually needed by ptoas (transitive closure under build dirs)
# it is smaller (<200 MB) than copying the full $LLVM_BUILD_DIR/lib (>700 MB)
ENV PTOAS_DEPS_DIR=/ptoas-deps
COPY docker/copy_ptoas_deps.sh /tmp/copy_ptoas_deps.sh
RUN mkdir -p $PTOAS_DEPS_DIR && bash /tmp/copy_ptoas_deps.sh

# -----------------------------------------------------------------------------
# Stage 2: verify wheel and ptoas in ascend/python image (no build tree)
# -----------------------------------------------------------------------------
# FROM quay.io/ascend/python:3.11-ubuntu22.04 AS runtime
FROM quay.io/ascend/cann:8.5.0-910b-ubuntu22.04-py3.11 AS runtime

# NOTE: both images work for `ptoas` and python bindings, difference are:
# - the `ascend/python` image is light-weight (only 500 MB) but lacks `bisheng` to compile cpp file generated by `ptoas`
# - the `ascend/cann` image has the full CANN for on-device execution, but is very big (10 GB)

# Copy only the wheel, ptoas binary, its .so dependencies, and test scripts from builder
COPY --from=builder /llvm-workspace/llvm-project/build-shared/tools/mlir/python_packages/mlir_core/wheelhouse/ptoas*.whl /tmp/
COPY --from=builder /llvm-workspace/PTOAS/build/tools/ptoas/ptoas /usr/local/bin/ptoas

RUN mkdir -p /usr/local/lib/ptoas
COPY --from=builder /ptoas-deps/. /usr/local/lib/ptoas/
ENV LD_LIBRARY_PATH=/usr/local/lib/ptoas:${LD_LIBRARY_PATH}

RUN pip install --no-cache-dir /tmp/ptoas*.whl && rm /tmp/ptoas*.whl

# test import without adjusting $PYTHONPATH and $LD_LIBRARY_PATH, in some irrelevant dir
WORKDIR /test
RUN python -c "import mlir.ir"
RUN python -c "from mlir.dialects import pto"

# same MatMul/Abs sample tests as in builder
COPY --from=builder /llvm-workspace/PTOAS/test/samples/MatMul/tmatmulk.py /sources/test/MatMul/
COPY --from=builder /llvm-workspace/PTOAS/test/samples/Abs/abs.py /sources/test/Abs/

WORKDIR /sources/test/MatMul
RUN python ./tmatmulk.py > ./tmatmulk.pto
RUN ptoas ./tmatmulk.pto -o ./tmatmulk.cpp

WORKDIR /sources/test/Abs
RUN python ./abs.py > ./abs.pto
RUN ptoas --enable-insert-sync ./abs.pto -o ./abs.cpp

# NOTE: if using the smaller `ascend/python` runtime image, can only run until here, cannot test bisheng usage below

# to compile cpp file generated by ptoas, need pto-isa headers
ARG PTO_ISA_COMMIT=c7b4e062639337fe42fe8f81a86ee7bd16740354
# on 2026/01/31: https://gitcode.com/cann/pto-isa/commit/c7b4e062639337fe42fe8f81a86ee7bd16740354?ref=master

WORKDIR /sources
RUN git clone https://gitcode.com/cann/pto-isa.git \
    && cd pto-isa && git checkout $PTO_ISA_COMMIT
ENV PTO_LIB_PATH=/sources/pto-isa
ENV BISHENG_OPTS="-I${PTO_LIB_PATH}/include/pto \
    -fPIC -shared -O2 -std=c++17 \
    --npu-arch=dav-2201 -DMEMORY_BASE"

WORKDIR /sources/test/Abs
RUN (echo '#if __CCE_AICORE__ == 220 && defined(__DAV_C220_VEC__)'; cat abs.cpp; echo '#endif') \
    > abs.cpp.tmp && mv abs.cpp.tmp abs.cpp
RUN bisheng $BISHENG_OPTS ./abs.cpp -o ./abs_kernel.so

WORKDIR /sources/test/MatMul
RUN (echo '#if __CCE_AICORE__ == 220 && defined(__DAV_C220_CUBE__)'; cat tmatmulk.cpp; echo '#endif') \
    > tmatmulk.cpp.tmp && mv tmatmulk.cpp.tmp tmatmulk.cpp
RUN bisheng $BISHENG_OPTS ./tmatmulk.cpp -o ./matmul_kernel.so

# add torch_npu to faciliate on-device testing during `docker run` (not used at build stage)
# for available versions see https://pypi.org/project/torch-npu/#history
RUN pip install --no-cache-dir torch==2.9.0 --index-url https://download.pytorch.org/whl/cpu \
    && pip install --no-cache-dir torch-npu==2.9.0 \
    && pip install --no-cache-dir numpy pyyaml

WORKDIR /sources/test/

CMD ["/bin/bash"]
